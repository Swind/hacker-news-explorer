---
story_id: 46832074
hn_url: https://news.ycombinator.com/item?id=46832074
title: "Show HN: I trained a 9M speech model to fix my Mandarin tones"
verdict: interesting
created_at: 2026-02-01T18:53:32
---

# Show HN: 训练9M参数模型修正普通话声调

## 📊 故事概览

- **分数**: 453 points
- **评论数**: 138条
- **发布日期**: 2026-01-31
- **作者**: simedw (个人开发者)

## 🔍 项目背景

作者因为学习普通话时难以掌握声调，且无法察觉自己的发音错误，决定训练一个语音模型来帮助自我纠正。这是一个典型的"开发者解决自身问题"的项目。

## 🛠️ 技术方案

### 核心架构
- **模型**: Conformer编码器（结合CNN和Transformer优势）
- **训练方法**: CTC (Connectionist Temporal Classification) 损失
- **参数规模**: 从75M成功压缩到**9M参数**
- **模型大小**: INT8量化后仅**11MB**
- **运行环境**: 完全在浏览器端运行

### 技术亮点

#### 1. **为什么选择Conformer？**
- CNN捕获局部声学特征（如卷舌音zh vs 齿龈音z）
- Transformer建模全局上下文（声调是相对的，受语境影响）
- 两者结合满足语音识别的双重需求

#### 2. **为什么使用CTC而非Seq2Seq？**
关键洞察：**语言学习需要"挑剔"而非"宽容"**

```
传统ASR（如Whisper）: 自动纠正错误 ✍️
→ "你发音错了，但我猜你想说什么"

CTC模型: 忠实记录发音 🎯
→ "你实际发什么音，我就输出什么"
```

对于发音训练，CTC的"固执"恰恰是优点。

#### 3. **创新Token设计**
- **不输出汉字**，而是拼音+声调作为独立token
- `zhong1` 和 `zhong4` 是完全不同的token
- 词汇表：1,254个拼音+声调组合（含轻声tone 5）
- 这样发音错误会被明确识别

#### 4. **压缩实验结果**

| 参数量 | TER | 声调准确率 |
|--------|-----|-----------|
| 75M    | 4.83% | 98.47% |
| 35M    | 5.16% | 98.36% |
| **9M** | 5.27% | 98.29% |

**关键发现**: 任务是数据受限而非计算受限，9M模型性能几乎无损。

#### 5. **强制对齐Bug修复**

**问题**: 开头静音导致置信度评分错误
```python
# 静音帧被错误分配给音节，导致blank概率掩盖真实发音
confidence = 0.0  # 错误！
```

**解决方案**: 过滤高blank概率帧
```python
def _filter_nonblank_frames(span_logp, blank_id=0, thr=0.7):
    p_blank = span_logp[:, blank_id].exp()
    keep = p_blank < thr
    return span_logp[keep] if keep.any() else span_logp
```

效果：置信度从 0.0 → 0.99 ✨

## 💡 技术洞察

### "苦涩教训"的又一例证
作者最初尝试基于规则的音高可视化（FFT + 启发式算法），但面临无数边界情况（噪音、协同发音、说话人变化等）。最终**学习表征击败手工规则**，验证了Sutton的"苦涩教训"。

### CTC的语言学习优势
ASR任务的"宽容"在CAPT（计算机辅助发音训练）场景下成为缺点。CTC逐帧输出概率的特性，使其不会"猜测"用户意图，而是忠实反映发音质量。

### 模型压缩的边际效益
9M vs 75M仅损失0.44%准确率，说明：
1. 该任务的复杂度适中
2. 数据质量比模型规模更重要
3. 端侧部署可行性强

### 识别到的局限性
- **母语者投诉**: 需要过度清晰发音才能通过（领域偏移：AISHELL主要是朗读语音）
- **儿童表现差**: 训练数据中儿童样本极少，音高范围不同
- **未来方向**: 加入Common Voice等对话数据集

## 🎯 创新点总结

1. **任务重定义**: 将ASR改造为发音评估，通过token设计实现
2. **端侧优先**: 从一开始就考虑浏览器部署，最终11MB实现
3. **工程实用**: 真实bug修复分享，不是"完美论文"
4. **个人驱动**: 开发者解决自身需求，展示独立技术能力

## 📈 HN讨论要点

### 技术讨论
- **CTC vs Attention解码**: 为什么不用Transducer？（CTC足够简单且有效）
- **声调建模**: 相对音高vs绝对音高，说话人归一化挑战
- **数据选择**: AISHELL质量评估，是否需要更口语化数据

### 应用场景
- **语言学习**: 普通话/泰语/越南语等声调语言通用性
- **辅助无障碍**: 听障人士的发音训练工具
- **可扩展性**: 其他方言或小语种适配

### 实现细节
- **浏览器性能**: onnxruntime-web兼容性
- **实时反馈**: 延迟vs精度权衡
- **隐私保护**: 本地处理无需云服务

## 🏆 评价

### 技术价值 ⭐⭐⭐⭐⭐
- 完整端到端实现（数据→训练→部署→优化）
- 模型压缩实验数据详实
- Bug修复过程具有学习价值

### 创新程度 ⭐⭐⭐⭐☆
- CTC用于发音训练的巧妙应用
- 拼音+声调token设计简单有效
- 不是学术突破，但工程优秀

### 实用性 ⭐⭐⭐⭐⭐
- 真实问题解决方案
- 可立即使用的demo
- 开源友好（架构公开）

### 社区价值 ⭐⭐⭐⭐⭐
- 详细的技术博客
- 可复现的实验
- 个人独立开发典范

## 🎓 最终结论

**判定**: **技术有趣 (Interesting)**

这是一个**教科书级别的个人技术项目**：
- 从真实痛点出发（学普通话声调难）
- 选择合适技术栈（Conformer+CTC）
- 工程实现扎实（9M→11MB）
- 分享详尽透明（含bug修复过程）
- 社区讨论质量高（138条评论）

**值得学习的方面**：
1. **问题重定义能力**: 把ASR变成发音评估
2. **端侧思维**: 压缩模型而非假设无限资源
3. **诚实分享**: 展示失败和bug，不只是成功
4. **完整产品**: 从算法到可用demo

**适用人群**：
- 语音识别开发者
- 语言学习应用开发者
- 模型压缩研究者
- 端侧AI工程师

---

**阅读建议**: 如果你对语音识别、模型压缩或语言学习技术感兴趣，这篇博客值得精读。作者的CTC for CAPT思路特别巧妙，值得借鉴到其他反馈类应用中。

**项目链接**: [Live Demo](https://simedw.com/) - 浏览器中直接运行，无需安装
